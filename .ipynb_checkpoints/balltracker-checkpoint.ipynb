{
 "metadata": {
  "name": "",
  "signature": "sha256:6105975ff774af490f82e94c9b6847104923f3f2d7736dc8e4bc0c7d0c9a3279"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Goal: Process video data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv\n",
      "import cv2\n",
      "import os\n",
      "import random\n",
      "import numpy as np\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_mov = \"%s/data/run000/backright.MOV\" % os.getcwd()\n",
      "filename_avi = \"%s/data/run000/backright.avi\" % os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vc = cv2.VideoCapture(filename_mov)\n",
      "vc.isOpened()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_frame(i):\n",
      "    vc.set(cv.CV_CAP_PROP_POS_FRAMES, i)\n",
      "    ret, img = vc.read()\n",
      "    return img"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_frame(capture, i):\n",
      "    capture.set(cv.CV_CAP_PROP_POS_FRAMES, i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_frame(f):\n",
      "    cv2.imshow('detection', f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cv2.namedWindow('detection', cv2.CV_WINDOW_AUTOSIZE)\n",
      "show_frame(get_frame(67))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cam = cv2.VideoCapture(filename_mov)            \n",
      "while True:\n",
      "    ret, img = cam.read()                      \n",
      "    if (type(img) == type(None)):\n",
      "        break\n",
      "\n",
      "    cv2.imshow('detection', img)\n",
      "    if (0xFF & cv2.waitKey(20) == 27) or img.size == 0:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np \n",
      "while True:\n",
      "    print \"here\"\n",
      "    ret, img = cam.read()  \n",
      "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    gray = np.float32(gray)\n",
      "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
      "\n",
      "while(cap.isOpened()):\n",
      "    ret, frame = cap.read()\n",
      "    \n",
      "    if frame is None:\n",
      "        continue\n",
      "        \n",
      "    print \"yes!\"\n",
      "\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    cv2.imshow('frame',gray)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cam' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-677fa205133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"here\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'cam' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "capture = cv2.VideoCapture(filename)\n",
      "while True:\n",
      "    ret, img = capture.read()\n",
      "\n",
      "#    result = processFrame(img)\n",
      "\n",
      "    cv2.imshow('some', result)\n",
      "    if 0xFF & cv2.waitKey(5) == 27:\n",
      "        break\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()\n",
      "cap.set(cv.CV_CAP_PROP_POS_FRAMES, 100)\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    cv2.imshow('frame', edges)\n",
      "\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('cannyframe2.png',frame2)\n",
      "        cv2.imwrite('cannyrgb.png',rgb)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    flow = cv2.calcOpticalFlowFarneback(prvs, next, 0.7, 1, 3, 5, 3, 5, 1, 0)\n",
      "\n",
      "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
      "    hsv[...,0] = ang*180/np.pi/2\n",
      "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
      "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
      "\n",
      "    cv2.imshow('frame2',rgb)\n",
      "    k = cv2.waitKey(30) & 0xFF\n",
      "    print k\n",
      "    if k == 27:\n",
      "        print \"ENDED\"\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('opticalfb.png',frame2)\n",
      "        cv2.imwrite('opticalhsv.png',rgb)\n",
      "    prvs = next"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "255\n",
        "112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "111"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "105"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-5bc06f3faa6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mang\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_HSV2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "# params for ShiTomasi corner detection\n",
      "feature_params = dict( maxCorners = 100,\n",
      "                       qualityLevel = 0.3,\n",
      "                       minDistance = 7,\n",
      "                       blockSize = 7 )\n",
      "\n",
      "# Parameters for lucas kanade optical flow\n",
      "lk_params = dict( winSize  = (15,15),\n",
      "                  maxLevel = 2,\n",
      "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
      "\n",
      "# Create some random colors\n",
      "color = np.random.randint(0,255,(100,3))\n",
      "\n",
      "# Take first frame and find corners in it\n",
      "ret, old_frame = cap.read()\n",
      "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
      "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
      "p0 = np.array([[[x,y]] for x in range(500,1000,40) for y in range(500,1000,40)])\n",
      "p0 = np.array([[[50,50]],[[100,200]],[[300,100]]])\n",
      "draw_points(p0, old_frame, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'draw_points' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-84-ac94f4eb7405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdraw_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'draw_points' is not defined"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a mask image for drawing purposes\n",
      "mask = np.zeros_like(old_frame)\n",
      "\n",
      "while(1):\n",
      "    ret,frame = cap.read()\n",
      "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # calculate optical flow\n",
      "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
      "    print p1\n",
      "    \n",
      "\n",
      "    # Select good points\n",
      "    good_new = p1[st==1]\n",
      "    good_old = p0[st==1]\n",
      "\n",
      "    # draw the tracks\n",
      "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
      "        a,b = new.ravel()\n",
      "        c,d = old.ravel()\n",
      "        cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
      "        cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
      "    img = cv2.add(frame,mask)\n",
      "    \n",
      "    print img\n",
      "\n",
      "    cv2.imshow('frame',img)\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        break\n",
      "\n",
      "    # Now update the previous frame and previous points\n",
      "    old_gray = frame_gray.copy()\n",
      "    p0 = good_new.reshape(-1,1,2)\n",
      "\n",
      "cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "error",
       "evalue": "/tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-e3a9fc6a9fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31merror\u001b[0m: /tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_points(p0, img, show=False):\n",
      "    img_with_points = img.copy()\n",
      "    for pt in p0:\n",
      "        a,b = tuple(pt[0])\n",
      "        cv2.circle(img_with_points, (int(a), int(b)), 10, (0,0,100), -1)\n",
      "    if show:\n",
      "        cv2.imshow('frame', img_with_points)\n",
      "    return img_with_points"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mouse callback function\n",
      "def print_points(event,x,y,flags,param):\n",
      "    if event == cv2.EVENT_LBUTTONDOWN:\n",
      "        print (x, y)\n",
      "        \n",
      "# Click point on frame to log it. \n",
      "def click_frame(i):\n",
      "    print \"Clicking Frame %d\"%i\n",
      "    cv2.namedWindow('image')\n",
      "    cv2.setMouseCallback('image', print_points)\n",
      "\n",
      "    while(1):\n",
      "        cv2.imshow('image', get_frame(i))\n",
      "        k = cv2.waitKey(-1) & 0xFF \n",
      "        if k == 27:\n",
      "            cv2.destroyAllWindows()\n",
      "            return True\n",
      "        elif k == 13:\n",
      "            cv2.destroyAllWindows()\n",
      "            return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(100, 1000):\n",
      "    if click_frame(i):\n",
      "        break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Clicking Frame 100\n",
        "(148, 480)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(304, 488)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Clicking Frame 101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(208, 485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(351, 488)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Don't know what this stuff is but it's cool. Potentially more features. \n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "img = get_frame(100)\n",
      "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
      "\n",
      "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
      "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
      "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
      "\n",
      "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
      "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
      "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
      "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
      "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distsq_between(p1, p2):\n",
      "    x1, y1 = p1\n",
      "    x2, y2 = p2\n",
      "    return (x1-x2)**2 + (y1-y2)**2\n",
      "\n",
      "def inbounds(p, img):\n",
      "    x, y = p\n",
      "    return x >= 0 and y >= 0 and x < img.shape[0] and y < img.shape[1]\n",
      "\n",
      "def get_points_in_radius(p1, r, img):\n",
      "    x1, y1 = p1\n",
      "    width, height = img.shape[:2]\n",
      "    return [(x,y) for x in xrange(x1-r, x1+r+1) for y in xrange(y1-r,y1+r+1) \n",
      "                  if distsq_between((x,y), p1) < r**2 and inbounds((x,y), img)]\n",
      "    \n",
      "    \n",
      "    #points_we_care_about = [point for point in all_points if distsq_between(point, (x1,y1)) < r**2 and inbounds(point, img)]\n",
      "    \n",
      "def get_average_color(p1, r, img):\n",
      "    return np.mean([img[point] for point in get_points_in_radius(p1, r, img)], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "color = get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "width, height = img.shape[:2]\n",
      "color = get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "#hsv = np.ones_like(img)\n",
      "#hsv = hsv*color\n",
      "image = np.array([[]])\n",
      "for i in range(0, height):\n",
      "    a = np.array([[]])\n",
      "    for j in range(0, height):\n",
      "        if(np.linalg.norm(img[i][j] - color) > 10):\n",
      "            a = np.concatenate(a, np.array([[0,0,0]]))\n",
      "            print a\n",
      "        else:\n",
      "            a = np.append(a, np.array([0,0,0]))\n",
      "    image = np.append(image, a)\n",
      "show_frame(image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "only length-1 arrays can be converted to Python scalars",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-14929f49f75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "print get_average_color((208, 485), int(math.sqrt(distsq_between((208, 485),(351, 488)))) , get_frame(101))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  57.84134843   80.16901501  110.50061891]\n",
        "[  61.50622303   83.8635606   115.6559185 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 52.13618279  67.37592361  96.73820621]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "for p in get_points_in_radius((0,0),5,img):\n",
      "    print img[p]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[13 41 70]\n",
        "[15 43 72]\n",
        "[28 41 74]\n",
        "[28 41 74]\n",
        "[41 41 78]\n",
        "[18 46 75]\n",
        "[18 46 75]\n",
        "[30 43 76]\n",
        "[30 43 76]\n",
        "[41 41 78]\n",
        "[17 49 69]\n",
        "[16 48 68]\n",
        "[29 48 74]\n",
        "[27 46 72]\n",
        "[35 41 75]\n",
        "[10 42 62]\n",
        "[11 43 63]\n",
        "[25 44 70]\n",
        "[24 43 69]\n",
        "[20 45 77]\n",
        "[20 45 77]\n",
        "[28 44 74]\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pykalman import KalmanFilter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def smooth(measurements):\n",
      "    kf = KalmanFilter(initial_state_mean=[-1,-1], n_dim_obs=len(measurements[0]))\n",
      "    return kf.em(measurements).smooth(measurements)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samples = np.random.multivariate_normal([-0.5, -0.5], [[1, 0],[0, 1]], 50)\n",
      "from matplotlib import pyplot as plt\n",
      "plt.plot(samples, color = 'red')\n",
      "plt.plot(smooth(samples), color = 'gray')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_edges(f, show = False):\n",
      "    next = cv2.cvtColor(f,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    if show:\n",
      "        cv2.imshow('frame', edges)\n",
      "        k = cv2.waitKey(-1) & 0xFF \n",
      "        cv2.destroyAllWindows()\n",
      "    return edges\n",
      "get_edges(get_frame(103))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "array([[0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       ..., \n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0],\n",
        "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(103)\n",
      "width, height = img.shape[:2]\n",
      "edges = get_edges(img)\n",
      "ysize = width/10.0\n",
      "z = int(width/ysize)\n",
      "r = width/10.0\n",
      "for i in range(0, z):\n",
      "    for j in range(0, 10):\n",
      "        x = width/10.0*i\n",
      "        y = height/10.0*j\n",
      "        print \"%d %d\"%(x, y)\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 0\n",
        "0 192\n",
        "0 384\n",
        "0 576\n",
        "0 768\n",
        "0 960\n",
        "0 1152\n",
        "0 1344\n",
        "0 1536\n",
        "0 1728\n",
        "108 0\n",
        "108 192\n",
        "108 384\n",
        "108 576\n",
        "108 768\n",
        "108 960\n",
        "108 1152\n",
        "108 1344\n",
        "108 1536\n",
        "108 1728\n",
        "216 0\n",
        "216 192\n",
        "216 384\n",
        "216 576\n",
        "216 768\n",
        "216 960\n",
        "216 1152\n",
        "216 1344\n",
        "216 1536\n",
        "216 1728\n",
        "324 0\n",
        "324 192\n",
        "324 384\n",
        "324 576\n",
        "324 768\n",
        "324 960\n",
        "324 1152\n",
        "324 1344\n",
        "324 1536\n",
        "324 1728\n",
        "432 0\n",
        "432 192\n",
        "432 384\n",
        "432 576\n",
        "432 768\n",
        "432 960\n",
        "432 1152\n",
        "432 1344\n",
        "432 1536\n",
        "432 1728\n",
        "540 0\n",
        "540 192\n",
        "540 384\n",
        "540 576\n",
        "540 768\n",
        "540 960\n",
        "540 1152\n",
        "540 1344\n",
        "540 1536\n",
        "540 1728\n",
        "648 0\n",
        "648 192\n",
        "648 384\n",
        "648 576\n",
        "648 768\n",
        "648 960\n",
        "648 1152\n",
        "648 1344\n",
        "648 1536\n",
        "648 1728\n",
        "756 0\n",
        "756 192\n",
        "756 384\n",
        "756 576\n",
        "756 768\n",
        "756 960\n",
        "756 1152\n",
        "756 1344\n",
        "756 1536\n",
        "756 1728\n",
        "864 0\n",
        "864 192\n",
        "864 384\n",
        "864 576\n",
        "864 768\n",
        "864 960\n",
        "864 1152\n",
        "864 1344\n",
        "864 1536\n",
        "864 1728\n",
        "972 0\n",
        "972 192\n",
        "972 384\n",
        "972 576\n",
        "972 768\n",
        "972 960\n",
        "972 1152\n",
        "972 1344\n",
        "972 1536\n",
        "972 1728\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "img = get_frame(103)\n",
      "original = cv2.cvtColor(f,cv2.COLOR_BGR2GRAY)\n",
      "retval, image = cv2.threshold(original, 50, 255, cv2.cv.CV_THRESH_BINARY)\n",
      "\n",
      "el = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
      "image = cv2.dilate(image, el, iterations=6)\n",
      "\n",
      "cv2.imwrite(\"dilated.png\", image)\n",
      "\n",
      "contours, hierarchy = cv2.findContours(\n",
      "    image,\n",
      "    cv2.cv.CV_RETR_LIST,\n",
      "    cv2.cv.CV_CHAIN_APPROX_SIMPLE\n",
      ")\n",
      "\n",
      "drawing = cv2.imread(\"test.jpg\")\n",
      "\n",
      "centers = []\n",
      "radii = []\n",
      "for contour in contours:\n",
      "    area = cv2.contourArea(contour)\n",
      "\n",
      "    # there is one contour that contains all others, filter it out\n",
      "    if area > 500:\n",
      "        continue\n",
      "\n",
      "    br = cv2.boundingRect(contour)\n",
      "    radii.append(br[2])\n",
      "\n",
      "    m = cv2.moments(contour)\n",
      "    center = (int(m['m10'] / m['m00']), int(m['m01'] / m['m00']))\n",
      "    centers.append(center)\n",
      "\n",
      "print(\"There are {} circles\".format(len(centers)))\n",
      "\n",
      "radius = int(np.average(radii)) + 5\n",
      "\n",
      "for center in centers:\n",
      "    cv2.circle(drawing, center, 3, (255, 0, 0), -1)\n",
      "    cv2.circle(drawing, center, radius, (0, 255, 0), 1)\n",
      "\n",
      "cv2.imwrite(\"drawing.png\", drawing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 43  40  41 ..., 103  98  95]\n",
        " [ 44  43  44 ..., 104  98  97]\n",
        " [ 45  44  44 ..., 102 100 100]\n",
        " ..., \n",
        " [ 63  63  61 ..., 154 155 158]\n",
        " [ 65  64  61 ..., 153 156 157]\n",
        " [ 65  64  61 ..., 154 154 157]]\n",
        "There are 0 circles\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "cannot convert float NaN to integer",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-115-aafa94bedac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There are {} circles\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}