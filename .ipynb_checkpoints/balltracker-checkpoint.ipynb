{
 "metadata": {
  "name": "",
  "signature": "sha256:f617b08b6c5cb9e9aab3473d82c17430470a3e8288679131ac67e3fb8ad60553"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Goal: Process video data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv\n",
      "import cv2\n",
      "import os\n",
      "import random\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_mov = \"%s/data/run000/backright.MOV\" % os.getcwd()\n",
      "filename_avi = \"%s/data/run000/backright.avi\" % os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vc = cv2.VideoCapture(filename_mov)\n",
      "vc.isOpened()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_frame(i):\n",
      "    vc.set(cv.CV_CAP_PROP_POS_FRAMES, i)\n",
      "    ret, img = vc.read()\n",
      "    return img"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_frame(capture, i):\n",
      "    capture.set(cv.CV_CAP_PROP_POS_FRAMES, i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_frame(f):\n",
      "    cv2.imshow('detection', f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cv2.namedWindow('detection', cv2.CV_WINDOW_AUTOSIZE)\n",
      "show_frame(get_frame(67))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cam = cv2.VideoCapture(filename_mov)            \n",
      "while True:\n",
      "    ret, img = cam.read()                      \n",
      "    if (type(img) == type(None)):\n",
      "        break\n",
      "\n",
      "    cv2.imshow('detection', img)\n",
      "    if (0xFF & cv2.waitKey(20) == 27) or img.size == 0:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np \n",
      "while True:\n",
      "    print \"here\"\n",
      "    ret, img = cam.read()  \n",
      "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    gray = np.float32(gray)\n",
      "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
      "\n",
      "while(cap.isOpened()):\n",
      "    ret, frame = cap.read()\n",
      "    \n",
      "    if frame is None:\n",
      "        continue\n",
      "        \n",
      "    print \"yes!\"\n",
      "\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    cv2.imshow('frame',gray)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cam' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-677fa205133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"here\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'cam' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "capture = cv2.VideoCapture(filename)\n",
      "while True:\n",
      "    ret, img = capture.read()\n",
      "\n",
      "#    result = processFrame(img)\n",
      "\n",
      "    cv2.imshow('some', result)\n",
      "    if 0xFF & cv2.waitKey(5) == 27:\n",
      "        break\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()\n",
      "cap.set(cv.CV_CAP_PROP_POS_FRAMES, 100)\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    cv2.imshow('frame', edges)\n",
      "\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('cannyframe2.png',frame2)\n",
      "        cv2.imwrite('cannyrgb.png',rgb)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    flow = cv2.calcOpticalFlowFarneback(prvs, next, 0.7, 1, 3, 5, 3, 5, 1, 0)\n",
      "\n",
      "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
      "    hsv[...,0] = ang*180/np.pi/2\n",
      "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
      "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
      "\n",
      "    cv2.imshow('frame2',rgb)\n",
      "    k = cv2.waitKey(30) & 0xFF\n",
      "    print k\n",
      "    if k == 27:\n",
      "        print \"ENDED\"\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('opticalfb.png',frame2)\n",
      "        cv2.imwrite('opticalhsv.png',rgb)\n",
      "    prvs = next"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "255\n",
        "112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "111"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "105"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-5bc06f3faa6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mang\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_HSV2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "# params for ShiTomasi corner detection\n",
      "feature_params = dict( maxCorners = 100,\n",
      "                       qualityLevel = 0.3,\n",
      "                       minDistance = 7,\n",
      "                       blockSize = 7 )\n",
      "\n",
      "# Parameters for lucas kanade optical flow\n",
      "lk_params = dict( winSize  = (15,15),\n",
      "                  maxLevel = 2,\n",
      "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
      "\n",
      "# Create some random colors\n",
      "color = np.random.randint(0,255,(100,3))\n",
      "\n",
      "# Take first frame and find corners in it\n",
      "ret, old_frame = cap.read()\n",
      "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
      "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
      "p0 = np.array([[[x,y]] for x in range(500,1000,40) for y in range(500,1000,40)])\n",
      "p0 = np.array([[[50,50]],[[100,200]],[[300,100]]])\n",
      "draw_points(p0, old_frame, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'draw_points' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-84-ac94f4eb7405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdraw_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'draw_points' is not defined"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a mask image for drawing purposes\n",
      "mask = np.zeros_like(old_frame)\n",
      "\n",
      "while(1):\n",
      "    ret,frame = cap.read()\n",
      "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # calculate optical flow\n",
      "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
      "    print p1\n",
      "    \n",
      "\n",
      "    # Select good points\n",
      "    good_new = p1[st==1]\n",
      "    good_old = p0[st==1]\n",
      "\n",
      "    # draw the tracks\n",
      "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
      "        a,b = new.ravel()\n",
      "        c,d = old.ravel()\n",
      "        cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
      "        cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
      "    img = cv2.add(frame,mask)\n",
      "    \n",
      "    print img\n",
      "\n",
      "    cv2.imshow('frame',img)\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        break\n",
      "\n",
      "    # Now update the previous frame and previous points\n",
      "    old_gray = frame_gray.copy()\n",
      "    p0 = good_new.reshape(-1,1,2)\n",
      "\n",
      "cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "error",
       "evalue": "/tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-e3a9fc6a9fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31merror\u001b[0m: /tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_points(p0, img, show=False):\n",
      "    img_with_points = img.copy()\n",
      "    for pt in p0:\n",
      "        a,b = tuple(pt[0])\n",
      "        cv2.circle(img_with_points, (int(a), int(b)), 10, (0,0,100), -1)\n",
      "    if show:\n",
      "        cv2.imshow('frame', img_with_points)\n",
      "    return img_with_points"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mouse callback function\n",
      "def print_points(event,x,y,flags,param):\n",
      "    if event == cv2.EVENT_LBUTTONDOWN:\n",
      "        print (x, y)\n",
      "        \n",
      "# Click point on frame to log it. \n",
      "def click_frame(i):\n",
      "    print \"Clicking Frame %d\"%i\n",
      "    cv2.namedWindow('image')\n",
      "    cv2.setMouseCallback('image', print_points)\n",
      "\n",
      "    while(1):\n",
      "        cv2.imshow('image', get_frame(i))\n",
      "        k = cv2.waitKey(-1) & 0xFF \n",
      "        if k == 27:\n",
      "            cv2.destroyAllWindows()\n",
      "            return True\n",
      "        elif k == 13:\n",
      "            cv2.destroyAllWindows()\n",
      "            return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(100, 1000):\n",
      "    if click_frame(i):\n",
      "        break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Clicking Frame 100\n",
        "(146, 487)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(300, 494)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(155, 365)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Clicking Frame 101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(206, 482)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(347, 493)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(200, 369)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Clicking Frame 102"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Don't know what this stuff is but it's cool. Potentially more features. \n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "img = get_frame(100)\n",
      "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
      "\n",
      "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
      "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
      "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
      "\n",
      "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
      "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
      "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
      "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
      "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distsq_between(p1, p2):\n",
      "    x1, y1 = p1\n",
      "    x2, y2 = p2\n",
      "    return (x1-x2)**2 + (y1-y2)**2\n",
      "\n",
      "def inbounds(p, img):\n",
      "    x, y = p\n",
      "    return x >= 0 and y >= 0 and x < img.shape[0] and y < img.shape[1]\n",
      "\n",
      "def get_points_we_care_about(p1, r, img):\n",
      "    x1, x2 = p1\n",
      "    width, height = img.shape[:2]\n",
      "    all_points = [(x,y) for x in xrange(x1-r, x1+r+1) for y in xrange(y1-r,y1+r+1) \n",
      "                  if distsq_between(point, p1) < r**2 and inbounds(point, img)]\n",
      "    points_we_care_about = [point for point in all_points if distsq_between(point, (x1,y1)) < r**2 and inbounds(point, img)]\n",
      "    \n",
      "\n",
      "def getColor(x1, y1, r, img):\n",
      "    print img[points_we_care_about[0]]\n",
      "    return np.mean([img[point] for point in points_we_care_about], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "range(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getColor(0,0,5, get_frame(100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[13 41 70]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "array([ 23.81818182,  43.81818182,  72.63636364])"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print get_frame(100)[]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[[ 18  46  75]\n",
        "  [ 18  46  75]\n",
        "  [ 30  43  76]\n",
        "  ..., \n",
        "  [ 85 102 117]\n",
        "  [ 85 102 117]\n",
        "  [ 85 102 117]]\n",
        "\n",
        " [[ 17  49  69]\n",
        "  [ 16  48  68]\n",
        "  [ 29  48  74]\n",
        "  ..., \n",
        "  [ 89  98 118]\n",
        "  [ 88  97 117]\n",
        "  [ 87  96 116]]\n",
        "\n",
        " [[ 10  42  62]\n",
        "  [ 11  43  63]\n",
        "  [ 25  44  70]\n",
        "  ..., \n",
        "  [ 86  95 115]\n",
        "  [ 85  94 114]\n",
        "  [ 85  94 114]]\n",
        "\n",
        " ..., \n",
        " [[ 26  38  83]\n",
        "  [ 26  38  83]\n",
        "  [ 31  42  82]\n",
        "  ..., \n",
        "  [ 94  97 114]\n",
        "  [ 94  97 114]\n",
        "  [ 94  97 114]]\n",
        "\n",
        " [[ 31  43  88]\n",
        "  [ 31  43  88]\n",
        "  [ 31  41  86]\n",
        "  ..., \n",
        "  [ 79  98 113]\n",
        "  [ 79  98 113]\n",
        "  [ 79  98 113]]\n",
        "\n",
        " [[ 28  40  85]\n",
        "  [ 28  40  85]\n",
        "  [ 31  41  86]\n",
        "  ..., \n",
        "  [ 78  97 112]\n",
        "  [ 78  97 112]\n",
        "  [ 78  97 112]]]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}