{
 "metadata": {
  "name": "",
  "signature": "sha256:c4ad63fed19107e42586e277c277fd4c2ad03bb2dc615bd9ff0f310de9a3afec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Goal: Process video data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv\n",
      "import cv2\n",
      "import os\n",
      "import random\n",
      "import numpy as np\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_mov = \"%s/data/run000/backright.MOV\" % os.getcwd()\n",
      "filename_avi = \"%s/data/run000/backright.avi\" % os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vc = cv2.VideoCapture(filename_mov)\n",
      "vc.isOpened()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_frame(i):\n",
      "    vc.set(cv.CV_CAP_PROP_POS_FRAMES, i)\n",
      "    ret, img = vc.read()\n",
      "    return img"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_frame(capture, i):\n",
      "    capture.set(cv.CV_CAP_PROP_POS_FRAMES, i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_frame(f):\n",
      "    cv2.imshow('detection', f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cv2.namedWindow('detection', cv2.CV_WINDOW_AUTOSIZE)\n",
      "show_frame(get_frame(67))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cam = cv2.VideoCapture(filename_mov)            \n",
      "while True:\n",
      "    ret, img = cam.read()                      \n",
      "    if (type(img) == type(None)):\n",
      "        break\n",
      "\n",
      "    cv2.imshow('detection', img)\n",
      "    if (0xFF & cv2.waitKey(20) == 27) or img.size == 0:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np \n",
      "while True:\n",
      "    print \"here\"\n",
      "    ret, img = cam.read()  \n",
      "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    gray = np.float32(gray)\n",
      "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
      "\n",
      "while(cap.isOpened()):\n",
      "    ret, frame = cap.read()\n",
      "    \n",
      "    if frame is None:\n",
      "        continue\n",
      "        \n",
      "    print \"yes!\"\n",
      "\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    cv2.imshow('frame',gray)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cam' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-677fa205133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"here\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'cam' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "capture = cv2.VideoCapture(filename)\n",
      "while True:\n",
      "    ret, img = capture.read()\n",
      "\n",
      "#    result = processFrame(img)\n",
      "\n",
      "    cv2.imshow('some', result)\n",
      "    if 0xFF & cv2.waitKey(5) == 27:\n",
      "        break\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()\n",
      "cap.set(cv.CV_CAP_PROP_POS_FRAMES, 100)\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    cv2.imshow('frame', edges)\n",
      "\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('cannyframe2.png',frame2)\n",
      "        cv2.imwrite('cannyrgb.png',rgb)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap, 100)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    flow = cv2.calcOpticalFlowFarneback(prvs, next, 0.7, 1, 3, 5, 3, 5, 1, 0)\n",
      "\n",
      "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
      "    hsv[...,0] = ang*180/np.pi/2\n",
      "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
      "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
      "\n",
      "    cv2.imshow('frame2',rgb)\n",
      "    k = cv2.waitKey(30) & 0xFF\n",
      "    print k\n",
      "    if k == 27:\n",
      "        print \"ENDED\"\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('opticalfb.png',frame2)\n",
      "        cv2.imwrite('opticalhsv.png',rgb)\n",
      "    prvs = next"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "255\n",
        "112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "111"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "105"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-5bc06f3faa6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mang\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_HSV2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "# params for ShiTomasi corner detection\n",
      "feature_params = dict( maxCorners = 100,\n",
      "                       qualityLevel = 0.3,\n",
      "                       minDistance = 7,\n",
      "                       blockSize = 7 )\n",
      "\n",
      "# Parameters for lucas kanade optical flow\n",
      "lk_params = dict( winSize  = (15,15),\n",
      "                  maxLevel = 2,\n",
      "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
      "\n",
      "# Create some random colors\n",
      "color = np.random.randint(0,255,(100,3))\n",
      "\n",
      "# Take first frame and find corners in it\n",
      "ret, old_frame = cap.read()\n",
      "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
      "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
      "p0 = np.array([[[x,y]] for x in range(500,1000,40) for y in range(500,1000,40)])\n",
      "p0 = np.array([[[50,50]],[[100,200]],[[300,100]]])\n",
      "draw_points(p0, old_frame, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'draw_points' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-84-ac94f4eb7405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdraw_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'draw_points' is not defined"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a mask image for drawing purposes\n",
      "mask = np.zeros_like(old_frame)\n",
      "\n",
      "while(1):\n",
      "    ret,frame = cap.read()\n",
      "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # calculate optical flow\n",
      "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
      "    print p1\n",
      "    \n",
      "\n",
      "    # Select good points\n",
      "    good_new = p1[st==1]\n",
      "    good_old = p0[st==1]\n",
      "\n",
      "    # draw the tracks\n",
      "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
      "        a,b = new.ravel()\n",
      "        c,d = old.ravel()\n",
      "        cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
      "        cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
      "    img = cv2.add(frame,mask)\n",
      "    \n",
      "    print img\n",
      "\n",
      "    cv2.imshow('frame',img)\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        break\n",
      "\n",
      "    # Now update the previous frame and previous points\n",
      "    old_gray = frame_gray.copy()\n",
      "    p0 = good_new.reshape(-1,1,2)\n",
      "\n",
      "cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "error",
       "evalue": "/tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-e3a9fc6a9fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31merror\u001b[0m: /tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_points(p0, img, show=False):\n",
      "    img_with_points = img.copy()\n",
      "    for pt in p0:\n",
      "        a,b = tuple(pt[0])\n",
      "        cv2.circle(img_with_points, (int(a), int(b)), 10, (0,0,100), -1)\n",
      "    if show:\n",
      "        cv2.imshow('frame', img_with_points)\n",
      "    return img_with_points"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mouse callback function\n",
      "def print_points(event,x,y,flags,param):\n",
      "    if event == cv2.EVENT_LBUTTONDOWN:\n",
      "        print (x, y)\n",
      "        \n",
      "# Click point on frame to log it. \n",
      "def click_frame(i):\n",
      "    print \"Clicking Frame %d\"%i\n",
      "    cv2.namedWindow('image')\n",
      "    cv2.setMouseCallback('image', print_points)\n",
      "\n",
      "    while(1):\n",
      "        cv2.imshow('image', get_frame(i))\n",
      "        k = cv2.waitKey(-1) & 0xFF \n",
      "        if k == 27:\n",
      "            cv2.destroyAllWindows()\n",
      "            return True\n",
      "        elif k == 13:\n",
      "            cv2.destroyAllWindows()\n",
      "            return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(100, 1000):\n",
      "    if click_frame(i):\n",
      "        break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Clicking Frame 100\n",
        "(148, 480)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(304, 488)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Clicking Frame 101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(208, 485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(351, 488)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Don't know what this stuff is but it's cool. Potentially more features. \n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "img = get_frame(100)\n",
      "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
      "\n",
      "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
      "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
      "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
      "\n",
      "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
      "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
      "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
      "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
      "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
      "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distsq_between(p1, p2):\n",
      "    x1, y1 = p1\n",
      "    x2, y2 = p2\n",
      "    return (x1-x2)**2 + (y1-y2)**2\n",
      "\n",
      "def inbounds(p, img):\n",
      "    x, y = p\n",
      "    return x >= 0 and y >= 0 and x < img.shape[0] and y < img.shape[1]\n",
      "\n",
      "def get_points_in_radius(p1, r, img):\n",
      "    x1, y1 = p1\n",
      "    height, width = img.shape[:2]\n",
      "    return [(x,y) for x in xrange(x1-r, x1+r+1) for y in xrange(y1-r,y1+r+1) \n",
      "                  if distsq_between((x,y), p1) < r**2 and inbounds((x,y), img)]\n",
      "        \n",
      "def get_average_color(p1, r, img):\n",
      "    return np.mean([img[point] for point in get_points_in_radius(p1, r, img)], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "color = get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "width, height = img.shape[:2]\n",
      "color = get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "#hsv = np.ones_like(img)\n",
      "#hsv = hsv*color\n",
      "image = np.array([[]])\n",
      "for i in range(0, height):\n",
      "    a = np.array([[]])\n",
      "    for j in range(0, height):\n",
      "        if(np.linalg.norm(img[i][j] - color) > 10):\n",
      "            a = np.concatenate(a, np.array([[0,0,0]]))\n",
      "            print a\n",
      "        else:\n",
      "            a = np.append(a, np.array([0,0,0]))\n",
      "    image = np.append(image, a)\n",
      "show_frame(image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "only length-1 arrays can be converted to Python scalars",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-14929f49f75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print get_average_color((148, 480), int(math.sqrt(distsq_between((148, 480),(304, 488)))) , get_frame(100))\n",
      "print get_average_color((208, 485), int(math.sqrt(distsq_between((208, 485),(351, 488)))) , get_frame(101))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  57.84134843   80.16901501  110.50061891]\n",
        "[  61.50622303   83.8635606   115.6559185 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 52.13618279  67.37592361  96.73820621]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(100)\n",
      "for p in get_points_in_radius((0,0),5,img):\n",
      "    print img[p]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[13 41 70]\n",
        "[15 43 72]\n",
        "[28 41 74]\n",
        "[28 41 74]\n",
        "[41 41 78]\n",
        "[18 46 75]\n",
        "[18 46 75]\n",
        "[30 43 76]\n",
        "[30 43 76]\n",
        "[41 41 78]\n",
        "[17 49 69]\n",
        "[16 48 68]\n",
        "[29 48 74]\n",
        "[27 46 72]\n",
        "[35 41 75]\n",
        "[10 42 62]\n",
        "[11 43 63]\n",
        "[25 44 70]\n",
        "[24 43 69]\n",
        "[20 45 77]\n",
        "[20 45 77]\n",
        "[28 44 74]\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pykalman import KalmanFilter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def smooth(measurements):\n",
      "    kf = KalmanFilter(initial_state_mean=[-1,-1], n_dim_obs=len(measurements[0]))\n",
      "    return kf.em(measurements).smooth(measurements)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samples = np.random.multivariate_normal([-0.5, -0.5], [[1, 0],[0, 1]], 50)\n",
      "from matplotlib import pyplot as plt\n",
      "plt.plot(samples, color = 'red')\n",
      "plt.plot(smooth(samples), color = 'gray')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_edges(f, show = False):\n",
      "    next = cv2.cvtColor(f,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    if show:\n",
      "        cv2.imshow('frame', edges)\n",
      "        k = cv2.waitKey(-1) & 0xFF \n",
      "        cv2.destroyAllWindows()\n",
      "    return edges"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = get_frame(103)\n",
      "height, width = img.shape[:2]\n",
      "edges = get_edges(img)\n",
      "ysize = height/10.0\n",
      "z = round(width/ysize)\n",
      "r1 = width/z\n",
      "r2 = height/10.0\n",
      "for i in range(0, int(z)):\n",
      "    for j in range(0, 10):\n",
      "        x = int(width/z*i)\n",
      "        y = int(height/10*j)\n",
      "        average_color = get_average_color((x,y), int(r1/2), img)\n",
      "        xs, ys = np.where(edges[x:x+r1][y:y+r2] > 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "capture = cv2.VideoCapture(filename_mov)\n",
      "print \"\\t Width: \",capture.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH)\n",
      "print \"\\t Height: \",capture.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT)\n",
      "print \"\\t FourCC: \",capture.get(cv2.cv.CV_CAP_PROP_FOURCC)\n",
      "print \"\\t Framerate: \",capture.get(cv2.cv.CV_CAP_PROP_FPS)\n",
      "numframes=capture.get(7)\n",
      "print \"\\t Number of Frames: \",numframes\n",
      "count=0\n",
      "history = 10\n",
      "nGauss = 3\n",
      "bgThresh = 0.6\n",
      "noise = 20\n",
      "bgs = cv2.BackgroundSubtractorMOG(history,nGauss,bgThresh,noise)\n",
      "measuredTrack=np.zeros((numframes,2))-1\n",
      "set_frame(capture, 100)\n",
      "while count<2000:\n",
      "    count+=1\n",
      "    img2 = capture.read()[1]\n",
      "    cv2.imshow(\"Video\",img2)\n",
      "    foremat=bgs.apply(img2)\n",
      "    cv2.waitKey(100)\n",
      "    foremat=bgs.apply(img2)\n",
      "    ret,thresh = cv2.threshold(foremat,127,255,0)\n",
      "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
      "    if len(contours) > 0:\n",
      "        m= np.mean(contours[0],axis=0)\n",
      "        measuredTrack[count-1,:]=m[0]\n",
      "        plt.plot(m[0,0],m[0,1],'ob')\n",
      "    cv2.imshow('Foreground',foremat)\n",
      "    cv2.waitKey(80)\n",
      "capture.release()\n",
      "print measuredTrack\n",
      "np.save(\"ballTrajectory\", measuredTrack)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t Width:  1920.0\n",
        "\t Height:  1080.0\n",
        "\t FourCC:  0.0\n",
        "\t Framerate:  24.0\n",
        "\t Number of Frames:  1558.72\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-184-0cdc32c90cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Video\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mforemat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_frame = get_frame(1)\n",
      "def get_background_sub(img, background=first_frame):\n",
      "    fgbg = cv2.BackgroundSubtractorMOG()\n",
      "    fgmask = fgbg.apply(background)\n",
      "    fgmask = fgbg.apply(img)\n",
      "    return fgmask\n",
      "def threshold_by_color(img):\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "cap = cv2.VideoCapture(filename_mov)\n",
      "set_frame(cap,100)\n",
      "while(1):\n",
      "\n",
      "    # Take each frame\n",
      "    _, frame = cap.read()\n",
      "\n",
      "    # Convert BGR to HSV\n",
      "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "\n",
      "    # define range of blue color in HSV\n",
      "    lower_blue = np.array([13, 183, 247])\n",
      "    upper_blue = np.array([255, 255, 255])\n",
      "\n",
      "    # Threshold the HSV image to get only blue colors\n",
      "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
      "\n",
      "    # Bitwise-AND mask and original image\n",
      "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
      "\n",
      "    cv2.imshow('frame',frame)\n",
      "    cv2.imshow('mask',mask)\n",
      "    cv2.imshow('res',res)\n",
      "    k = cv2.waitKey(5) & 0xFF\n",
      "    if k == 27:\n",
      "        break\n",
      "\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hsv = cv2.cvtColor(get_frame(100), cv2.COLOR_BGR2HSV)\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hsv[148][480]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 252,
       "text": [
        "array([ 14, 147, 113], dtype=uint8)"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = get_frame(100)\n",
      "b = a[360:610, 0:300]\n",
      "hsv = cv2.cvtColor(b, cv2.COLOR_BGR2HSV)\n",
      "print hsv[50][50]\n",
      "cv2.imshow('hi', hsv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 13 183 247]\n"
       ]
      }
     ],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}