{
 "metadata": {
  "name": "",
  "signature": "sha256:f49ba008ef480e7690c40923f4d8703a257a6cffd023005f51a14d3c6e546a5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Goal: Process video data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv\n",
      "import cv2\n",
      "import os\n",
      "import random\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_mov = \"%s/data/run000/backright.MOV\" % os.getcwd()\n",
      "filename_avi = \"%s/data/run000/backright.avi\" % os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vc = cv2.VideoCapture(filename_mov)\n",
      "vc.isOpened()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_frame(i):\n",
      "    vc.set(cv.CV_CAP_PROP_POS_FRAMES, i)\n",
      "    ret, img = vc.read()\n",
      "    return img"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_frame(f):\n",
      "    cv2.imshow('detection', f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cv2.namedWindow('detection', cv2.CV_WINDOW_AUTOSIZE)\n",
      "show_frame(get_frame(67))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cam = cv2.VideoCapture(filename_mov)            \n",
      "while True:\n",
      "    ret, img = cam.read()                      \n",
      "    if (type(img) == type(None)):\n",
      "        break\n",
      "\n",
      "    cv2.imshow('detection', img)\n",
      "    if (0xFF & cv2.waitKey(20) == 27) or img.size == 0:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np \n",
      "while True:\n",
      "    print \"here\"\n",
      "    ret, img = cam.read()  \n",
      "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    gray = np.float32(gray)\n",
      "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
      "\n",
      "while(cap.isOpened()):\n",
      "    ret, frame = cap.read()\n",
      "    \n",
      "    if frame is None:\n",
      "        continue\n",
      "        \n",
      "    print \"yes!\"\n",
      "\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    cv2.imshow('frame',gray)\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cam' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-677fa205133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"here\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'cam' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "capture = cv2.VideoCapture(filename)\n",
      "while True:\n",
      "    ret, img = capture.read()\n",
      "\n",
      "#    result = processFrame(img)\n",
      "\n",
      "    cv2.imshow('some', result)\n",
      "    if 0xFF & cv2.waitKey(5) == 27:\n",
      "        break\n",
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()\n",
      "cap.set(cv.CV_CAP_PROP_POS_FRAMES, 100)\n",
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "    edges = cv2.Canny(next, 10, 100)\n",
      "    cv2.imshow('frame', edges)\n",
      "\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        cv2.destroyAllWindows()\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('cannyframe2.png',frame2)\n",
      "        cv2.imwrite('cannyrgb.png',rgb)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "ret, frame1 = cap.read()\n",
      "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
      "hsv = np.zeros_like(frame1)\n",
      "hsv[...,1] = 255\n",
      "print prvs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 58  57  54 ..., 108 108 107]\n",
        " [ 57  55  55 ..., 108 108 107]\n",
        " [ 53  54  56 ..., 106 107 107]\n",
        " ..., \n",
        " [ 64  60  57 ..., 168 169 167]\n",
        " [ 67  60  56 ..., 170 172 168]\n",
        " [ 66  63  59 ..., 173 174 169]]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "while(1):\n",
      "    ret, frame2 = cap.read()\n",
      "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    flow = cv2.calcOpticalFlowFarneback(prvs, next, 0.5, 1, 3, 15, 3, 5, 1, 0)\n",
      "\n",
      "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
      "    hsv[...,0] = ang*180/np.pi/2\n",
      "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
      "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
      "\n",
      "    cv2.imshow('frame2',rgb)\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        break\n",
      "    elif k == ord('s'):\n",
      "        cv2.imwrite('opticalfb.png',frame2)\n",
      "        cv2.imwrite('opticalhsv.png',rgb)\n",
      "    prvs = next"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-ebcfabdcb70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowFarneback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "cap = cv2.VideoCapture(filename_mov)\n",
      "\n",
      "# params for ShiTomasi corner detection\n",
      "feature_params = dict( maxCorners = 100,\n",
      "                       qualityLevel = 0.3,\n",
      "                       minDistance = 7,\n",
      "                       blockSize = 7 )\n",
      "\n",
      "# Parameters for lucas kanade optical flow\n",
      "lk_params = dict( winSize  = (15,15),\n",
      "                  maxLevel = 2,\n",
      "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
      "\n",
      "# Create some random colors\n",
      "color = np.random.randint(0,255,(100,3))\n",
      "\n",
      "# Take first frame and find corners in it\n",
      "ret, old_frame = cap.read()\n",
      "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
      "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
      "p0 = np.array([[[x,y]] for x in range(500,1000,40) for y in range(500,1000,40)])\n",
      "p0 = np.array([[[50,50]],[[100,200]],[[300,100]]])\n",
      "draw_points(p0, old_frame, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "array([[[ 25,  47,  91],\n",
        "        [ 24,  46,  90],\n",
        "        [ 24,  43,  87],\n",
        "        ..., \n",
        "        [ 80, 106, 121],\n",
        "        [ 76, 107, 122],\n",
        "        [ 75, 106, 121]],\n",
        "\n",
        "       [[ 24,  46,  90],\n",
        "        [ 22,  44,  88],\n",
        "        [ 25,  44,  88],\n",
        "        ..., \n",
        "        [ 80, 106, 121],\n",
        "        [ 76, 107, 122],\n",
        "        [ 75, 106, 121]],\n",
        "\n",
        "       [[ 24,  46,  78],\n",
        "        [ 25,  47,  79],\n",
        "        [ 27,  49,  81],\n",
        "        ..., \n",
        "        [ 78, 103, 121],\n",
        "        [ 77, 105, 123],\n",
        "        [ 77, 105, 123]],\n",
        "\n",
        "       ..., \n",
        "       [[ 76,  82,  25],\n",
        "        [ 72,  78,  21],\n",
        "        [ 69,  75,  18],\n",
        "        ..., \n",
        "        [191, 175, 145],\n",
        "        [194, 176, 146],\n",
        "        [192, 174, 144]],\n",
        "\n",
        "       [[ 76,  85,  27],\n",
        "        [ 69,  78,  20],\n",
        "        [ 68,  74,  17],\n",
        "        ..., \n",
        "        [184, 180, 146],\n",
        "        [186, 182, 148],\n",
        "        [182, 178, 144]],\n",
        "\n",
        "       [[ 75,  84,  26],\n",
        "        [ 72,  81,  23],\n",
        "        [ 71,  77,  20],\n",
        "        ..., \n",
        "        [187, 183, 149],\n",
        "        [188, 184, 150],\n",
        "        [183, 179, 145]]], dtype=uint8)"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a mask image for drawing purposes\n",
      "mask = np.zeros_like(old_frame)\n",
      "\n",
      "while(1):\n",
      "    ret,frame = cap.read()\n",
      "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # calculate optical flow\n",
      "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
      "    print p1\n",
      "    \n",
      "\n",
      "    # Select good points\n",
      "    good_new = p1[st==1]\n",
      "    good_old = p0[st==1]\n",
      "\n",
      "    # draw the tracks\n",
      "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
      "        a,b = new.ravel()\n",
      "        c,d = old.ravel()\n",
      "        cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
      "        cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
      "    img = cv2.add(frame,mask)\n",
      "    \n",
      "    print img\n",
      "\n",
      "    cv2.imshow('frame',img)\n",
      "    k = cv2.waitKey(30) & 0xff\n",
      "    if k == 27:\n",
      "        break\n",
      "\n",
      "    # Now update the previous frame and previous points\n",
      "    old_gray = frame_gray.copy()\n",
      "    p0 = good_new.reshape(-1,1,2)\n",
      "\n",
      "cv2.destroyAllWindows()\n",
      "cap.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "error",
       "evalue": "/tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-e3a9fc6a9fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31merror\u001b[0m: /tmp/opencv-x9eh/opencv-2.4.8.2/modules/video/src/lkpyramid.cpp:593: error: (-215) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function calcOpticalFlowPyrLK\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_points(p0, img, show=False):\n",
      "    img_with_points = img.copy()\n",
      "    for pt in p0:\n",
      "        a,b = tuple(pt[0])\n",
      "        cv2.circle(img_with_points, (int(a), int(b)), 10, (0,0,100), -1)\n",
      "    if show:\n",
      "        cv2.imshow('frame', img_with_points)\n",
      "    return img_with_points"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}